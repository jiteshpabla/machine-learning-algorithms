{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sml_project1_VER1.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn-VMfw0qSoN",
        "colab_type": "code",
        "outputId": "aed331f2-217f-4e11-fb3f-093cefcc55d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!ls\n",
        "# download dataset\n",
        "!gdown https://drive.google.com/uc?id=1bqT04uGQKVfbBd9Ru_Wtku8BqhCKY1Vo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist_data.mat\tsample_data\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bqT04uGQKVfbBd9Ru_Wtku8BqhCKY1Vo\n",
            "To: /content/mnist_data.mat\n",
            "88.7MB [00:00, 243MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFG2R6ofqqbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TqRnV_zq_Kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the dataset\n",
        "data = scipy.io.loadmat(\"mnist_data.mat\") \n",
        "#type(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPECyaLhss1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert dataset to numpy arrays\n",
        "tr_x = np.array(data[\"trX\"])\n",
        "tr_y = np.array(data[\"trY\"])\n",
        "ts_x = np.array(data[\"tsX\"])\n",
        "ts_y = np.array(data[\"tsY\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twc9QPc3wrvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#func for visualizing any 1 image\n",
        "def visualizing_one_img(pixels): #input any ts_x or tr_x imag into this function\n",
        "  #pixels = ts_x[1500]\n",
        "  #pixels = np.array(pixels) #if not already converted to np array\n",
        "  #print(len(pixels)) # 784 pixels per image\n",
        "\n",
        "  # reshaping to 28x28\n",
        "  pixels = pixels.reshape((28, 28))\n",
        "\n",
        "  # plotting\n",
        "  plt.imshow(pixels, cmap='gray')\n",
        "  plt.show()\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOrMgBIczlzJ",
        "colab_type": "code",
        "outputId": "f8f091ad-6ce0-4146-c939-da0ad032dfea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#TRAINING data\n",
        "#this variable is where the input features (mean and std-dev) of every image will be stored\n",
        "tr_x_avg_stddev = []\n",
        "\n",
        "for index, img in enumerate(tr_x): #enumerate to get both index and array\n",
        "  average_val = np.mean(img)\n",
        "  stddev_val = np.std(img)\n",
        "  tr_x_avg_stddev.append([average_val, stddev_val])\n",
        "\n",
        "tr_x_avg_stddev = np.array(tr_x_avg_stddev)\n",
        "print"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function print>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFWH7NRNihNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#doing the same for TEST data\n",
        "ts_x_avg_stddev = []\n",
        "for index, img in enumerate(ts_x): #enumerate to get both index and array\n",
        "  average_val = np.mean(img)\n",
        "  stddev_val = np.std(img)\n",
        "  ts_x_avg_stddev.append([average_val, stddev_val])\n",
        "\n",
        "ts_x_avg_stddev = np.array(ts_x_avg_stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCBGfEIh9OJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################################################################\n",
        "#--------------------------------------------------LOGISTIC REGRESSION----------------------------------------------------\n",
        "##########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_vtBk0Nqbmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for implementing the logistic function\n",
        "def logistic_func(wghts, input_x):\n",
        "  return 1.0/(1 + np.exp(-np.dot(input_x, wghts.T))) \n",
        "\n",
        "#function for calculating the gradient of the log likelyhood function directly using formula\n",
        "def log_gradient(wghts, input_x, y):\n",
        "  return np.dot((logistic_func(wghts, input_x) - y.reshape(input_x.shape[0], -1)).T, input_x)\n",
        "\n",
        "#fucntion for updating weights\n",
        "def logistic_regression(input_x, y, wghts, lr=.001):\n",
        "  #running the gradient ascent for 1000 iterations\n",
        "  for i in range(0,1000):\n",
        "    wghts = wghts - (lr * log_gradient(wghts, input_x, y)) \n",
        "\n",
        "  return wghts\n",
        "\n",
        "#fucntion for applying the threshold and giving final output\n",
        "def predict_logistic_regression_values(wghts, input_x):\n",
        "  output_val = logistic_func(wghts, input_x)\n",
        "  for i, val in enumerate(output_val):\n",
        "    if val >= 0.5:\n",
        "      output_val[i] = 1\n",
        "    else:\n",
        "      output_val[i] = 0\n",
        "  return output_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV7jHbTQqgXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_wghts = np.matrix(np.random.rand(tr_x_avg_stddev.shape[1]))\n",
        "wghts = np.matrix(np.zeros(tr_x_avg_stddev.shape[1]))\n",
        "\n",
        "wghts = logistic_regression(tr_x_avg_stddev, tr_y, init_wghts)\n",
        "#print(wghts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8p_jvUMOdyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to calculate the confusion matrix from given true values and predicted values\n",
        "def compute_confusion_matrix(true, pred):\n",
        "  #the vlaues in the matrix\n",
        "  #row 0 [ correct pred 7      wrong pred 7]\n",
        "  #row 1 [ wring pred 8        correct pred 8]\n",
        "  result = np.array([[0,0],[0,0]])\n",
        "  for i, val in enumerate(true):\n",
        "    if val == 0:\n",
        "      if pred[i] == 0: \n",
        "        result[0][0] += 1\n",
        "      else:\n",
        "        result[0][1] += 1\n",
        "    elif val == 1:\n",
        "      if pred[i] == 0:\n",
        "        result[1][0] += 1\n",
        "      else:\n",
        "        result[1][1] += 1\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa4CnvBYtLKc",
        "colab_type": "code",
        "outputId": "151c8fe5-536f-40bd-81ed-5fe8210680fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#calculating accuracy from confusion matrix\n",
        "#on test data\n",
        "y_pred = predict_logistic_regression_values(wghts, ts_x_avg_stddev)\n",
        "#cm = metrics.confusion_matrix(ts_y.T, y_pred)\n",
        "cm = compute_confusion_matrix(ts_y.T, y_pred)\n",
        "#print(cm)\n",
        "accuracy = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\n",
        "accuracy_class0 = (cm[0][0]) / (cm[0][0] + cm[0][1])\n",
        "accuracy_class1 = (cm[1][1]) / (cm[1][0] + cm[1][1])\n",
        "print(\"LOGISTIC REGRESSION\")\n",
        "print(\"accuracy for 7:\", accuracy_class0)\n",
        "print(\"accuracy for 8:\", accuracy_class1)\n",
        "print(\"accuracy:\", accuracy)\n",
        "'''\n",
        "#on training data\n",
        "y_pred_tr = predict_logistic_regression_values(wghts, tr_x_avg_stddev)\n",
        "#cm_tr = metrics.confusion_matrix(tr_y.T, y_pred_tr)\n",
        "cm_tr = compute_confusion_matrix(tr_y.T, y_pred_tr)\n",
        "print(cm_tr)\n",
        "accuracy_tr = (cm_tr[0][0] + cm_tr[1][1])/(cm_tr[0][0] + cm_tr[0][1] + cm_tr[1][0] + cm_tr[1][1])\n",
        "print(accuracy_tr)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOGISTIC REGRESSION\n",
            "accuracy for 7: 0.8005836575875487\n",
            "accuracy for 8: 0.6735112936344969\n",
            "accuracy: 0.7387612387612388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#on training data\\ny_pred_tr = predict_logistic_regression_values(wghts, tr_x_avg_stddev)\\n#cm_tr = metrics.confusion_matrix(tr_y.T, y_pred_tr)\\ncm_tr = compute_confusion_matrix(tr_y.T, y_pred_tr)\\nprint(cm_tr)\\naccuracy_tr = (cm_tr[0][0] + cm_tr[1][1])/(cm_tr[0][0] + cm_tr[0][1] + cm_tr[1][0] + cm_tr[1][1])\\nprint(accuracy_tr)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy2HZn706I0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################################################################\n",
        "#------------------------------------------------------NAIVE BAYES--------------------------------------------------------\n",
        "##########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx2cETNEgSDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero_count = 0\n",
        "one_count = 0\n",
        "for i in tr_y.T:\n",
        "  if i[0] == 0:\n",
        "    zero_count = zero_count + 1\n",
        "  else:\n",
        "    one_count = one_count + 1\n",
        "\n",
        "#probablities of both the output lables\n",
        "zero_prob = zero_count/len(tr_y.T) #prob of 7s\n",
        "one_prob = one_count/len(tr_y.T) #prob of 8s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVwocUHSndUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tr_x_avg_stddev --- index 0 is avg; 1 is stddev\n",
        "\n",
        "#variable nomenclature = class_feature_mean/var\n",
        "\n",
        "#MEANS\n",
        "#for zero/7 class\n",
        "zero_avg_mean = 0\n",
        "zero_stddev_mean = 0\n",
        "#for one/8 class\n",
        "one_avg_mean = 0\n",
        "one_stddev_mean = 0\n",
        "\n",
        "#VARIANCES\n",
        "#for zero/7 class\n",
        "zero_avg_var = 0\n",
        "zero_stddev_var = 0\n",
        "#for one/8 class\n",
        "one_avg_var = 0\n",
        "one_stddev_var = 0\n",
        "\n",
        "#for class zero/7\n",
        "#tr_x_avg_stddev.T is cut from 0 to zero_count\n",
        "#MEANS\n",
        "zero_avg_mean = np.mean(tr_x_avg_stddev.T[0][:zero_count])\n",
        "zero_stddev_mean = np.mean(tr_x_avg_stddev.T[1][:zero_count])\n",
        "#VARIANCES\n",
        "zero_avg_var = np.var(tr_x_avg_stddev.T[0][:zero_count])\n",
        "zero_stddev_var = np.var(tr_x_avg_stddev.T[1][:zero_count])\n",
        "\n",
        "#for class one/8\n",
        "#tr_x_avg_stddev.T is cut from zero_count to end of matrix\n",
        "#MEANS\n",
        "one_avg_mean = np.mean(tr_x_avg_stddev.T[0][zero_count:])\n",
        "one_stddev_mean = np.mean(tr_x_avg_stddev.T[1][zero_count:])\n",
        "#VARIANCES\n",
        "one_avg_var = np.var(tr_x_avg_stddev.T[0][zero_count:]) #these values are = 0?\n",
        "one_stddev_var = np.var(tr_x_avg_stddev.T[1][zero_count:]) #these values are = 0?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfAMaZr3oQBZ",
        "colab_type": "code",
        "outputId": "5d01aa53-a503-43b2-db52-bdabff6b743e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "#variable nomenclature = class_feature_mean/var\n",
        "\n",
        "#-------for zero/7 class\n",
        "print(\"distribution parameters for class-zero/digit 7\")\n",
        "#distribution parameters for the avg\n",
        "print(\"mean for 'average':\", zero_avg_mean)\n",
        "print(\"variance for 'average':\", zero_avg_var)\n",
        "#distribution parameters for the avg\n",
        "print(\"mean for 'std-deviation':\", zero_stddev_mean)\n",
        "print(\"variance for 'std-deviation':\", zero_stddev_var)\n",
        "#-------\n",
        "#-------for class one/8\n",
        "print(\"distribution parameters for class-one/digit 8\")\n",
        "#distribution parameters for the avg\n",
        "print(\"mean for 'average':\", one_avg_mean)\n",
        "print(\"variance for 'average':\", one_avg_var)\n",
        "#distribution parameters for the avg\n",
        "print(\"mean for 'std-deviation':\", one_stddev_mean)\n",
        "print(\"variance for 'std-deviation':\", one_stddev_var)\n",
        "#-------"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distribution parameters for class-zero/digit 7\n",
            "mean for 'average': 0.11452769775108769\n",
            "variance for 'average': 0.0009383442174894415\n",
            "mean for 'std-deviation': 0.28755656517748474\n",
            "variance for 'std-deviation': 0.0014593227954204646\n",
            "distribution parameters for class-one/digit 8\n",
            "mean for 'average': 0.1501559818936975\n",
            "variance for 'average': 0.0014924691579640671\n",
            "mean for 'std-deviation': 0.3204758364888714\n",
            "variance for 'std-deviation': 0.001596807543708563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1I-5YGuGJWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for calulating p(x|y)\n",
        "def p_of_x_given_y(x, mean_y, variance_y):\n",
        "    # implementation of the probability density function fro gaussian normal distribution\n",
        "    p = 1/(np.sqrt(2*np.pi*variance_y)) * np.exp((-(x-mean_y)**2)/(2*variance_y))\n",
        "    return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ODNDrTvp-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#function for the implementation of the naive bayes formula\n",
        "def naive_bayes(feature_avg, feature_stddev):\n",
        "  #probability of input being in class zero/7\n",
        "  input_is_in_zero = zero_prob * p_of_x_given_y(feature_avg, zero_avg_mean, zero_avg_var) * p_of_x_given_y(feature_stddev, zero_stddev_mean, zero_stddev_var)\n",
        "  #probability of input being in class one/8\n",
        "  input_is_in_one = one_prob * p_of_x_given_y(feature_avg, one_avg_mean, one_avg_var) * p_of_x_given_y(feature_stddev, one_stddev_mean, one_stddev_var)\n",
        "\n",
        "  #classify\n",
        "  if input_is_in_one > input_is_in_zero:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#function for giving out the final naive bayes predicted values\n",
        "def predict_naive_bayes_values(input_x):\n",
        "  output_vector = []\n",
        "  for input_img_features in input_x:\n",
        "    output_vector.append(naive_bayes(input_img_features[0], input_img_features[1]))\n",
        "  return np.array(output_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHt0j4xq_XdN",
        "colab_type": "code",
        "outputId": "00ed9a73-6ccb-4b92-b4d2-e594292991ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#calculating accuracy from the confusion matrix\n",
        "#on test data\n",
        "y_pred = predict_naive_bayes_values(ts_x_avg_stddev)\n",
        "cm = compute_confusion_matrix(ts_y.T, y_pred)\n",
        "#print(cm)\n",
        "accuracy = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\n",
        "accuracy_class0 = (cm[0][0]) / (cm[0][0] + cm[0][1])\n",
        "accuracy_class1 = (cm[1][1]) / (cm[1][0] + cm[1][1])\n",
        "print(\"NAIVE BAYES\")\n",
        "print(\"accuracy for 7:\", accuracy_class0)\n",
        "print(\"accuracy for 8:\", accuracy_class1)\n",
        "print(\"accuracy:\", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAIVE BAYES\n",
            "accuracy for 7: 0.7597276264591439\n",
            "accuracy for 8: 0.6273100616016427\n",
            "accuracy: 0.6953046953046953\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}